{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import csv\n",
    "from sklearn import svm, metrics\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "myfile = np.genfromtxt('/home/hju/advanceBio/largedata/data_mirna_rna_onlylabel.csv', delimiter=\",\", dtype=int) # cols: label, ID, race, mirnas...\n",
    "data = myfile[1:, 1:]  # data: n_samples * n_features array; LAST COL OF CSV IS nan (after the last comma)\n",
    "labels = myfile[1:, 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "********************** 0 **********************\n",
      "total sample: 942\n",
      "training dataset: 0.75, testing dataset: 0.25\n",
      "dead in total dataset: 0.14\n",
      "dead in training dataset: 0.15, dead in testing dataset: 0.12\n",
      "\n",
      "=== Logistic Regression ===\n",
      "score: 0.8177966101694916\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/hju/anaconda3/lib/python3.7/site-packages/sklearn/svm/base.py:196: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== SVC rbf ===\n",
      "score: 0.8771186440677966\n",
      "\n",
      "=== SVC linear ===\n",
      "score: 0.788135593220339\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/hju/anaconda3/lib/python3.7/site-packages/sklearn/svm/base.py:196: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== SVC poly 3 ===\n",
      "score: 0.7923728813559322\n",
      "\n",
      "=== Random Forest ===\n",
      "score: 0.8771186440677966\n",
      "\n",
      "********************** 1 **********************\n",
      "total sample: 942\n",
      "training dataset: 0.75, testing dataset: 0.25\n",
      "dead in total dataset: 0.14\n",
      "dead in training dataset: 0.15, dead in testing dataset: 0.14\n",
      "\n",
      "=== Logistic Regression ===\n",
      "score: 0.809322033898305\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/hju/anaconda3/lib/python3.7/site-packages/sklearn/svm/base.py:196: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== SVC rbf ===\n",
      "score: 0.8601694915254238\n",
      "\n",
      "=== SVC linear ===\n",
      "score: 0.788135593220339\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/hju/anaconda3/lib/python3.7/site-packages/sklearn/svm/base.py:196: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== SVC poly 3 ===\n",
      "score: 0.7923728813559322\n",
      "\n",
      "=== Random Forest ===\n",
      "score: 0.8686440677966102\n",
      "\n",
      "********************** 2 **********************\n",
      "total sample: 942\n",
      "training dataset: 0.75, testing dataset: 0.25\n",
      "dead in total dataset: 0.14\n",
      "dead in training dataset: 0.14, dead in testing dataset: 0.17\n",
      "\n",
      "=== Logistic Regression ===\n",
      "score: 0.7838983050847458\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/hju/anaconda3/lib/python3.7/site-packages/sklearn/svm/base.py:196: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== SVC rbf ===\n",
      "score: 0.8347457627118644\n",
      "\n",
      "=== SVC linear ===\n",
      "score: 0.7838983050847458\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/hju/anaconda3/lib/python3.7/site-packages/sklearn/svm/base.py:196: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== SVC poly 3 ===\n",
      "score: 0.809322033898305\n",
      "\n",
      "=== Random Forest ===\n",
      "score: 0.8305084745762712\n",
      "\n",
      "********************** 3 **********************\n",
      "total sample: 942\n",
      "training dataset: 0.75, testing dataset: 0.25\n",
      "dead in total dataset: 0.14\n",
      "dead in training dataset: 0.14, dead in testing dataset: 0.15\n",
      "\n",
      "=== Logistic Regression ===\n",
      "score: 0.7796610169491526\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/hju/anaconda3/lib/python3.7/site-packages/sklearn/svm/base.py:196: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== SVC rbf ===\n",
      "score: 0.8516949152542372\n",
      "\n",
      "=== SVC linear ===\n",
      "score: 0.7796610169491526\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/hju/anaconda3/lib/python3.7/site-packages/sklearn/svm/base.py:196: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== SVC poly 3 ===\n",
      "score: 0.7627118644067796\n",
      "\n",
      "=== Random Forest ===\n",
      "score: 0.8347457627118644\n",
      "\n",
      "********************** 4 **********************\n",
      "total sample: 942\n",
      "training dataset: 0.75, testing dataset: 0.25\n",
      "dead in total dataset: 0.14\n",
      "dead in training dataset: 0.15, dead in testing dataset: 0.14\n",
      "\n",
      "=== Logistic Regression ===\n",
      "score: 0.7966101694915254\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/hju/anaconda3/lib/python3.7/site-packages/sklearn/svm/base.py:196: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== SVC rbf ===\n",
      "score: 0.864406779661017\n",
      "\n",
      "=== SVC linear ===\n",
      "score: 0.8008474576271186\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/hju/anaconda3/lib/python3.7/site-packages/sklearn/svm/base.py:196: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== SVC poly 3 ===\n",
      "score: 0.8220338983050848\n",
      "\n",
      "=== Random Forest ===\n",
      "score: 0.8686440677966102\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for i in range(5):\n",
    "    print(\"********************** %d **********************\" % i)\n",
    "    data_train, data_test, label_train, label_test = train_test_split(data, labels, test_size=0.25, random_state=i, shuffle=True)\n",
    "\n",
    "    count_dead_train = 0\n",
    "    count_dead_test = 0\n",
    "    for k in range(label_train.shape[0]):\n",
    "        if label_train[k] == 1:\n",
    "            count_dead_train += 1\n",
    "    for k in range(label_test.shape[0]):\n",
    "        if label_test[k] == 1:\n",
    "            count_dead_test += 1\n",
    "    \n",
    "    print(\"total sample: %d\" % (label_train.shape[0]+label_test.shape[0]))\n",
    "    sz1 = label_train.shape[0]/(label_train.shape[0]+label_test.shape[0])\n",
    "    sz2 = label_test.shape[0]/(label_train.shape[0]+label_test.shape[0])\n",
    "    print(\"training dataset: %.2f, testing dataset: %.2f\" % (sz1, sz2))\n",
    "    sz0 = (count_dead_train+count_dead_test)/(label_train.shape[0]+label_test.shape[0])\n",
    "    sz1 = count_dead_train/label_train.shape[0]\n",
    "    sz2 = count_dead_test/label_test.shape[0]\n",
    "    print(\"dead in total dataset: %.2f\" % sz0)\n",
    "    print(\"dead in training dataset: %.2f, dead in testing dataset: %.2f\" % (sz1, sz2))\n",
    "    print()\n",
    "\n",
    "    #================ Logistic Regression ==================\n",
    "    logr = LogisticRegression(solver='lbfgs', n_jobs = 2)\n",
    "    logr.fit(data_train, label_train)\n",
    "    # predicted = logr.predict(data_test)\n",
    "    # logr.predict_proba(X[:2, :])\n",
    "    logr_score = logr.score(data_test, label_test)\n",
    "\n",
    "    print ('=== Logistic Regression ===')\n",
    "    print(f'score: {logr_score}')\n",
    "    # print(f'expected: {label_test}')\n",
    "    # print(f'predicted: {predicted}')\n",
    "    print()\n",
    "\n",
    "    #================== SVM =============================\n",
    "    svcc = svm.SVC(kernel = 'rbf')\n",
    "    svcc.fit(data_train, label_train)\n",
    "    # predicted = classifier.predict(data_test)\n",
    "    # expected = labels[-num_test:]\n",
    "    svcc_score = svcc.score(data_test, label_test)\n",
    "\n",
    "    print ('=== SVC rbf ===')\n",
    "    # print(\"Classification report for classifier %s:\\n%s\\n\"\n",
    "    #       % (classifier, metrics.classification_report(label_test, predicted)))\n",
    "    # print(\"Confusion matrix:\\n%s\" % metrics.confusion_matrix(label_test, predicted))\n",
    "    # print(f'expected: {label_test}')\n",
    "    # print(f'predicted: {predicted}')\n",
    "    print(f'score: {svcc_score}')\n",
    "    print()\n",
    "    #------------------------------------------------\n",
    "    svcc = svm.SVC(kernel = 'linear')\n",
    "    svcc.fit(data_train, label_train)\n",
    "    # predicted = svc.predict(data_test)\n",
    "    # expected = labels[-num_test:]\n",
    "    svcc_score = svcc.score(data_test, label_test)\n",
    "\n",
    "    print ('=== SVC linear ===')\n",
    "    # print(\"Classification report for classifier %s:\\n%s\\n\"\n",
    "    #       % (classifier, metrics.classification_report(label_test, predicted)))\n",
    "    # print(\"Confusion matrix:\\n%s\" % metrics.confusion_matrix(label_test, predicted))\n",
    "    # print(f'expected: {label_test}')\n",
    "    # print(f'predicted: {predicted}')\n",
    "    print(f'score: {svcc_score}')\n",
    "    print()\n",
    "    #------------------------------------------------\n",
    "    svcc = svm.SVC(kernel = 'poly', degree = 3)\n",
    "    svcc.fit(data_train, label_train)\n",
    "    svcc_score = svcc.score(data_test, label_test)\n",
    "    # predicted = svc.predict(data_test)\n",
    "    # expected = labels[-num_test:]\n",
    "\n",
    "    print ('=== SVC poly 3 ===')\n",
    "    # print(\"Classification report for classifier %s:\\n%s\\n\"\n",
    "    #       % (classifier, metrics.classification_report(label_test, predicted)))\n",
    "    # print(\"Confusion matrix:\\n%s\" % metrics.confusion_matrix(label_test, predicted))\n",
    "    # print(f'expected: {label_test}')\n",
    "    # print(f'predicted: {predicted}')\n",
    "    print(f'score: {svcc_score}')\n",
    "    print()\n",
    "\n",
    "    #======================= Random Forest =========================\n",
    "    rf = RandomForestClassifier(n_estimators=10)\n",
    "    #clf = RandomForestClassifier(n_estimators= 10)\n",
    "    rf = rf.fit(data_train, label_train)\n",
    "    # predicted = clf.predict(data_test)\n",
    "    rf_score = rf.score(data_test, label_test)\n",
    "\n",
    "    # importances = clf.feature_importances_\n",
    "    # std = np.std([tree.feature_importances_ for tree in clf.estimators_],\n",
    "    #              axis=0)\n",
    "    # indices = np.argsort(importances)[::-1]\n",
    "\n",
    "    print ('=== Random Forest ===')\n",
    "    # print(f'expected: {label_test}')\n",
    "    # print(f'predicted: {predicted}')\n",
    "    print(f'score: {rf_score}')\n",
    "    print()\n",
    "\n",
    "    # # Plot the feature importances of the forest\n",
    "    # plt.figure()\n",
    "    # plt.title(\"RF Feature importances\")\n",
    "    # plt.bar(range(data_train.shape[1]), importances[indices],\n",
    "    #        color=\"r\", yerr=std[indices], align=\"center\")\n",
    "    # plt.xticks(range(data_train.shape[1]), indices)\n",
    "    # plt.xlim([-1, data_train.shape[1]])\n",
    "    # # plt.savefig(\"RF_importance.png\")\n",
    "    # plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
